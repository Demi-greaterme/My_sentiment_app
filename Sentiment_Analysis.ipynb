{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqXj6oNxkn8iPj5lCucuD8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Demi-greaterme/My_sentiment_app/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "\n",
        "!pip install newspaper3k\n",
        "!pip install nltk\n",
        "!pip install lxml_html_clean\n",
        "!pip install spacy\n",
        "!pip install transformers\n",
        "!pip install scikit-learn\n",
        "!pip install datasets\n",
        "!pip install hf-xet\n",
        "!pip install streamlit\n",
        "!pip install scikit-learn\n",
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import datasets\n",
        "import joblib\n",
        "from newspaper import Article\n",
        "from transformers import pipeline\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import DistilBertForSequenceClassification\n",
        "from transformers import DistilBertTokenizerFast\n",
        "from transformers import Trainer, TrainingArguments\n",
        "nltk.download('punkt_tab')\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gqg78V1mAsp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraping sentences\n",
        "\n",
        "URL = \"https://www.theguardian.com/news/2025/jun/03/mrbeast-jimmy-donaldson-youtube-videos-star\"\n",
        "\n",
        "article = Article(URL)\n",
        "article.download()\n",
        "article.parse()\n",
        "article.nlp()\n",
        "\n",
        "text = article.text\n",
        "print(text)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "X2ULUN0jQNFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_raw_text_to_cleaned_sentences(raw_text_input):\n",
        "    if not raw_text_input or not isinstance(raw_text_input, str):\n",
        "        return []\n",
        "\n",
        "    text_normalized_quotes = raw_text_input.replace(\"â€™\", \"'\").replace(\"â€˜\", \"'\").replace(\"`\", \"'\")\n",
        "    doc = nlp(text_normalized_quotes)\n",
        "\n",
        "    cleaned_sentences = []\n",
        "    for sent in doc.sents:\n",
        "        sentence_text = sent.text\n",
        "        cleaned = re.sub(r\"[^a-zA-Z0-9\\s\\.,!'\\\"?\\-()]\", \"\", sentence_text)\n",
        "        cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
        "        cleaned = cleaned.lower()\n",
        "        if cleaned: # Add only if not empty after cleaning\n",
        "            cleaned_sentences.append(cleaned)\n",
        "    return cleaned_sentences"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PEXdcmGY-lrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting rid of special characters\n",
        "cleaned_sentences = process_raw_text_to_cleaned_sentences(text)\n",
        "print(len(cleaned_sentences))\n",
        "print(cleaned_sentences[:25])"
      ],
      "metadata": {
        "id": "yVnEhHg1Svif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dataset for the snetences\n",
        "df = pd.DataFrame({'sentence': cleaned_sentences})\n",
        "\n",
        "df.to_csv('labeled_sentences.csv', index=False)"
      ],
      "metadata": {
        "id": "3HTK7Nkjb44e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"labeled_sentences.csv\")\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "\n",
        "df['label'] = df['sentence'].apply(lambda x: classifier(x)[0]['label'])\n",
        "\n",
        "df.to_csv(\"labeled_sentences.csv\", index=False)"
      ],
      "metadata": {
        "id": "1zcXdjAzNa4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "KQa4vTN-TcB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skewness = df['label'].value_counts()\n",
        "\n",
        "sns.barplot(x=skewness.index, y=skewness.values)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aCvF77jWBdot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling categorical variables\n",
        "\n",
        "label_map = {'label_0': 0, 'label_1': 1, 'label_2': 2}\n",
        "\n",
        "df['label'] = df['label'].map(label_map)\n",
        "\n",
        "dataset = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "id": "JQWoz45zEReG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization + splitting\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch['sentence'], padding=True, truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
        "\n",
        "dataset_split = tokenized_dataset.train_test_split(test_size=0.2)\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)"
      ],
      "metadata": {
        "id": "2U21LYt6OsHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n"
      ],
      "metadata": {
        "id": "eMU6Q2zNfImx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"distilbert/distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "sentiment_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "demo_text = \"I had so much fun yesterday!\"\n",
        "\n",
        "prediction = sentiment_pipeline(demo_text)\n",
        "print(prediction)\n"
      ],
      "metadata": {
        "id": "JHPmMaEch0yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Sentiment Analysis System\")\n",
        "st.subheader(\"Enter text below to analyze its sentiment\")\n",
        "\n",
        "# User input\n",
        "user_input = st.text_area(\"Input Text\", \"Type here...\")\n",
        "\n",
        "if st.button(\"Analyze Sentiment\"):\n",
        "    if user_input:\n",
        "        blob = TextBlob(user_input)\n",
        "        sentiment_score = blob.sentiment.polarity\n",
        "\n",
        "        if sentiment_score > 0:\n",
        "            sentiment = \"Positive ðŸ˜Š\"\n",
        "        elif sentiment_score < 0:\n",
        "            sentiment = \"Negative ðŸ˜ž\"\n",
        "        else:\n",
        "            sentiment = \"Neutral ðŸ˜\"\n",
        "\n",
        "        st.success(f\"Sentiment: {sentiment}\")\n",
        "        st.info(f\"Sentiment Score: {sentiment_score:.2f}\")\n",
        "    else:\n",
        "        st.warning(\"Please enter text to analyze.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3KfPOJLCFaM",
        "outputId": "36f4237a-302e-4c55-f8e7-1ae3f410e4f6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-08 19:34:03.683 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-08 19:34:03.949 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-06-08 19:34:03.950 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-08 19:34:03.953 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-08 19:34:03.955 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-08 19:34:03.956 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-08 19:34:03.957 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-08 19:34:03.958 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-08 19:34:03.959 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-08 19:34:03.960 Session state does not function when running a script without `streamlit run`\n",
            "2025-06-08 19:34:03.961 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-08 19:34:03.962 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-08 19:34:03.964 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-08 19:34:03.965 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-08 19:34:03.966 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-08 19:34:03.967 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-06-08 19:34:03.968 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('model.joblib', 'wb') as f:\n",
        "    joblib.dump(model, f)"
      ],
      "metadata": {
        "id": "t6s2qQpZh9zY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m71O_iy2CcaD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}